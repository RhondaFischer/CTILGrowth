{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c44891",
   "metadata": {},
   "source": [
    "# Luminaries Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b632468",
   "metadata": {},
   "source": [
    "Working attempt at updating code to only pull tweets after the last tweet id for a user or after a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce84d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import pytz\n",
    "import tweepy as tw\n",
    "from tweepy import Cursor # Used to perform pagination\n",
    "from tweepy import OAuthHandler # Used for authentication\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "string.punctuation\n",
    "\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb51c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_KEY = \n",
    "TWITTER_SECRET = \n",
    "TWITTER_BEARER_TOKEN = \n",
    "ACCESS_TOKEN = \n",
    "ACCESS_TOKEN_SECRET = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36216b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the previous luminaries tweets file to get the last Tweet ID for each Luminary\n",
    "\n",
    "client = tweepy.Client(bearer_token=TWITTER_BEARER_TOKEN)\n",
    "auth = tweepy.OAuthHandler(TWITTER_KEY, TWITTER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "client2 = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "#auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "#api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "def get_tweepy_api():\n",
    "    auth = tweepy.OAuthHandler(TWITTER_KEY, TWITTER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    return tweepy.API(auth, wait_on_rate_limit=True, retry_count=10, retry_delay=3)\n",
    "\n",
    "api = get_tweepy_api()\n",
    "tweet_result_df2 = pd.read_csv(\"full_tcc_lumin_tweets.csv\", index_col=0)\n",
    "#lumin_maxid = tweet_result_df2.groupby(by = 'screen_name').tweet_id.max().reset_index()\n",
    "lumin_maxid = tweet_result_df2.groupby(by = ['screen_name', 'user_id']).tweet_id.max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying an approach that uses a query and date since, works for hashtag, \n",
    "# but how for Luminaries?\n",
    "new_search = '#wildfires -filter:retweets'\n",
    "date_since = \"2022-02-15\"\n",
    "tweets = tw.Cursor(client2.search, \n",
    "                           q=new_search,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71bc1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving variable start and end dates, saving column names from previous export\n",
    "lumin_maxid.columns=['handle', 'user_id','maxid']\n",
    "s_time = '2022-01-01T00:00:00Z'\n",
    "e_time = '2022-02-14T00:00:00Z'\n",
    "col_names = list(tweet_result_df2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8027d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lumin_list=list(lumin_maxid['handle'][0:5])\n",
    "userid_list = list(lumin_maxid['user_id'][0:5])\n",
    "maxid_list = list(lumin_maxid['maxid'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c962f095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2474021983"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5efda6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_results_df = {\n",
    "    'tweet_text': [], 'tweet_id': [], 'created_at': [], 'tweet_yr': [], 'tweet_mo':[], 'tweet_mo_nbr':[],\n",
    "    'tweet_day': [], 'tweet_hr': [],'tweet_day_of_week':[] ,'tweet_dow_nbr':[], 'tweet_date': [], 'is_extended_tweet': [],\n",
    "    'is_retweet': [], 'is_quote_tweet': [], 'url_count': [], 'hashtag_count': [], 'lang': [],\n",
    "    'user_id': [], 'screen_name': [], 'link_to_tweet': [], 'followers_count': [],\n",
    "    'friends_count': [], 'user_created_at': [], 'user_statuses_count': [], 'user_tweets_per_day': [],\n",
    "    'user_age_days': [], 'retweet_count': [], 'favorite_count': [], 'rechecked_time': []\n",
    "}\n",
    "\n",
    "col_names = list(tweet_results_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0198a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used in original Luminaries script, expects columns that are missing from the new scrips\n",
    "\n",
    "month_dict = {'Jan':'1', 'Feb':'2', 'Mar':'3', 'Apr':'4', 'May':'5', 'Jun': '6', \n",
    "              'Jul': '7', 'Aug': '8', 'Sep': '9', 'Oct':'10', 'Nov':'11', 'Dec':'12' }\n",
    "day_of_week = {'Sun':'1', 'Mon':'2', 'Tue':'3', 'Wed': '4', 'Thu': '5', 'Fri':'6', 'Sat':'7'}\n",
    "def process_lumin_tweet(status,is_retweeted):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        status = status._json\n",
    "    except AttributeError as error:\n",
    "        pass\n",
    "    \n",
    "    #tweet_data = {}\n",
    "    tweet_data = pd.DataFrame(columns = [col_names])\n",
    "    #print(status)\n",
    "    try:\n",
    "        tweet_text = (status[\"extended_tweet\"][\"full_text\"]).strip().replace('\\n', ' ').replace('\\r', '').replace(',', '').replace(u'â€™', u\"'\")\n",
    "        is_extended=True\n",
    "    except KeyError:\n",
    "        tweet_text = (status[\"full_text\"]).strip().replace('\\n', ' ').replace('\\r', '').replace(',', '').replace(u'â€™', u\"'\")\n",
    "        is_extended=False\n",
    "        \n",
    "    tweet_id = str(status[\"id\"])\n",
    "    created_at = status[\"created_at\"]\n",
    "    tweet_yr = created_at[-4:-1]+created_at[-1]\n",
    "    tweet_mo = created_at[4:7]\n",
    "    tweet_mo_nbr = month_dict[tweet_mo]\n",
    "    tweet_day = created_at[8:10]\n",
    "    tweet_day_of_week = created_at[0:3]\n",
    "    tweet_dow_nbr = day_of_week[tweet_day_of_week]\n",
    "    tweet_hr = created_at[11:13]\n",
    "    s = \"-\"\n",
    "    seq = (tweet_yr, tweet_mo_nbr, tweet_day)\n",
    "    tweet_date = s.join(seq)\n",
    "    is_extended_tweet = is_extended\n",
    "    is_retweet = is_retweeted\n",
    "    is_quote_tweet = hasattr(status, \"quoted_status\")\n",
    "    lang = status[\"lang\"]\n",
    "    \n",
    "    if is_extended:\n",
    "        url_count = len(status[\"extended_tweet\"][\"entities\"][\"urls\"])\n",
    "        hashtag_count = len(status[\"extended_tweet\"][\"entities\"][\"hashtags\"])\n",
    "    else:\n",
    "        url_count = len(status[\"entities\"][\"urls\"])\n",
    "        hashtag_count = len(status[\"entities\"][\"hashtags\"])\n",
    "    \n",
    "    user_json = status[\"user\"]\n",
    "    \n",
    "    user_id = str(user_json[\"id\"])\n",
    "    screen_name = user_json[\"screen_name\"]\n",
    "    link_to_tweet = \"https://twitter.com/{}/status/{}\".format(tweet_data[\"screen_name\"], status[\"id\"])\n",
    "    followers_count = user_json[\"followers_count\"]\n",
    "    friends_count = user_json[\"friends_count\"]\n",
    "    user_created_at = user_json[\"created_at\"]\n",
    "    user_statuses_count = user_json[\"statuses_count\"]\n",
    "    user_age_days = ((datetime.utcnow().replace(tzinfo=pytz.utc) - datetime.strptime(user_json['created_at'], \"%a %b %d %H:%M:%S %z %Y\")).days)\n",
    "    try:\n",
    "        tweets_per_day = user_json['statuses_count'] / user_age_days\n",
    "    except ZeroDivisionError:\n",
    "        tweets_per_day = 0\n",
    "    user_tweets_per_day = tweets_per_day\n",
    "    user_age_days = user_age_days\n",
    "    \n",
    "    retweet_count = status[\"retweet_count\"]\n",
    "    favorite_count = status[\"favorite_count\"]\n",
    "    rechecked_time = ((datetime.utcnow().replace(tzinfo=pytz.utc)))\n",
    "    \n",
    "    tweet_list = [tweet_text,\n",
    "                  tweet_id,\n",
    "                  created_at,\n",
    "                  tweet_yr,\n",
    "                  tweet_mo,\n",
    "                  tweet_mo_nbr,\n",
    "                  tweet_day,\n",
    "                  tweet_hr,\n",
    "                  tweet_day_of_week,\n",
    "                  tweet_dow_nbr,\n",
    "                  tweet_date,\n",
    "                 is_extended_tweet,\n",
    "                 is_retweet,\n",
    "                 is_quote_tweet,\n",
    "                 url_count,\n",
    "                 hashtag_count,\n",
    "                 lang,\n",
    "                 user_id,\n",
    "                 screen_name,\n",
    "                 link_to_tweet,\n",
    "                 followers_count,\n",
    "                 friends_count,\n",
    "                 user_created_at,\n",
    "                 user_statuses_count,\n",
    "                 user_tweets_per_day,\n",
    "                 user_age_days,\n",
    "                 retweet_count,\n",
    "                 favorite_count,\n",
    "                 rechecked_time]\n",
    "    #print(\"tweet_list\", tweet_list)\n",
    "\n",
    "    return tweet_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13f651",
   "metadata": {},
   "source": [
    "## Below are various attempts all work in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6ba0492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7CsHealth\n",
      "[<Tweet id=1491681314113835009 text=Lâ€™Institut BergoniÃ©, Exolis et Synapse Medicine s'allient dans le tÃ©lÃ©suivi des patients atteints de cancer via @rteston https://t.co/nhqmTS8U3F https://t.co/bS9zFEkW0l>, <Tweet id=1491085678301569027 text=Nouveau DMP : le service Mon Espace SantÃ© interroge sur la sÃ©curitÃ© des donnÃ©es https://t.co/xjfRiJVJAP https://t.co/g8hJB4VoBg>, <Tweet id=1491083917838934025 text=Des chercheurs dÃ©veloppent un utÃ©rus artificiel gÃ©rÃ© par une IA https://t.co/U9x7aBZ8oF https://t.co/h7ABtnFnQ4>, <Tweet id=1490998350514200581 text=Le Pr Fabrice Denis, crÃ©ateur primÃ© de https://t.co/vRLLiar7OW : Â«Â nous ne sommes quâ€™aux balbutiements de la e-santÃ©Â Â» https://t.co/3nTEhZOC9v https://t.co/KtsPt8vakA>, <Tweet id=1490988107369492485 text=Le CNOM publie un guide de la santÃ© numÃ©rique via @rteston https://t.co/tX8UMGgxCB https://t.co/tOWp5vSbI7>, <Tweet id=1490988069939556355 text=Une nouvelle appli, truffÃ©e dâ€™IA qui sÃ©lectionne les publications mÃ©dicales qui vous concernent ! Du 100% pur jus de science gratuit ! via @Francois_BARRAU https://t.co/jpdR0DiWZo https://t.co/kJ45ROK8GS>, <Tweet id=1490972177637781506 text=Comment la France rattrape son retard dans le numÃ©rique en santÃ© https://t.co/ka03Z9AtWQ https://t.co/eiqkPqPIJY>, <Tweet id=1490744122050809866 text=Coalition Next lance un nouvel appel Ã  projets https://t.co/BJ2OzLm073 https://t.co/5QJuiByqY3>, <Tweet id=1490723297545314311 text=[TRIBUNE] Intelligence artificielle et e-santÃ© : vers une innovation thÃ©rapeutique socialement responsable https://t.co/VhF6PPrPHA https://t.co/d9l08yxFq6>, <Tweet id=1490721528832409601 text=Avec le rachat de 8fit, Withings veut se dÃ©velopper dans les services autour de la santÃ© https://t.co/aDQy1iG7UH https://t.co/L3hqN81vcY>]\n",
      "ATLHealthLawyer\n",
      "[<Tweet id=1491889275620761606 text=. @Polsinelli Health Care Antitrust Year in Review\n",
      "\n",
      " https://t.co/MT4l8GfBee>, <Tweet id=1491851405430296586 text=RT @Polsinelli: Read the latest Tech Transactions &amp; Data Privacy 2022 Report containing articles that highlight the forward-thinking adviceâ€¦>, <Tweet id=1491410312184147972 text=Highmark Healthâ€™s Report On Savings Tied To Fraud, Abuse Efforts Sparks Controversy\n",
      "\n",
      " https://t.co/gGuv1buAvZ>, <Tweet id=1491403077345230852 text=Provider Relief Fund Expected To Run Out In Coming Months https://t.co/k0NL9kIXsC>, <Tweet id=1490336036358078471 text=This makes me want to forgive the @LEGO_Group piece I stepped on this morning. ðŸ˜†\n",
      "\n",
      "LEGO Is Giving Hospitals MRI Scanner Sets to Ease Kidsâ€™ Worries https://t.co/A0Rj7QFtEy via @https://nerdist.com>, <Tweet id=1489389201728622593 text=Invitation @Polsinelliâ€™s The True Cost of Manufacturer #340B Contract Pharmacy Restrictions Webinar â€“ 2.17.22\n",
      "\n",
      "https://t.co/e4ij8bq53U>, <Tweet id=1488491089254363139 text=Iâ€™m excited for the opportunity to work with Suhail and Amanda again, this time @polsinelli #ATL. Welcome! https://t.co/MrOgVnbZWG>, <Tweet id=1488155776787136515 text=Lawmakers, Advocates Urge Biden Administration To Add Medicare Coverage For At-Home Coronavirus Tests https://t.co/I2xi4Q28rm>, <Tweet id=1487139636463947783 text=LAST CHANCE TO REGISTER: Medical Staff Leaders and their Legal Advisors: Managing Todayâ€™s Challenges 2022 Virtual Conference - Session 3\n",
      "\n",
      " https://t.co/66c9wb5ry9>, <Tweet id=1487040230125445120 text=Medicare Patients Win the Right to Appeal Gap in Nursing Home Coverage - Kaiser Health News https://t.co/bcK3RrUaD3>]\n",
      "AaronMiri\n",
      "[<Tweet id=1493009151890497536 text=@rwang0 Good.  Itâ€™s time we cut through the nonsense and go back to common sense America .  Glad to see this>, <Tweet id=1493007301736898565 text=@rwang0 @TheRock @SUPER Ultimate showmanship . Super impressive @TheRock ðŸ˜Ž>, <Tweet id=1492976782965985282 text=ðŸ¤£ðŸ”¥ðŸ˜Ž https://t.co/AmjfxlJcap>, <Tweet id=1492690997356253187 text=@ValaAfshar @NASA @RexChapman https://t.co/EMN9H2Fvaa>, <Tweet id=1492642456420204544 text=@rwang0 @Tesla #tesla https://t.co/eK27wbOwHN>, <Tweet id=1492600302918418434 text=Go on little man! ðŸ¦¾ðŸ”¥ https://t.co/0WdcdGYb6G>, <Tweet id=1492561977209757698 text=@rwang0 @Tedla https://t.co/1cOmYiA7HB>, <Tweet id=1492531664538505216 text=@jayferro @LinkedIn @TimHuff @JasonRedmanWW Iâ€™m a fan.  #darkmode for all ðŸ¦¾>, <Tweet id=1492528106409758724 text=@jayferro @LinkedIn @TimHuff @JasonRedmanWW I was today years old when I realized @linkedin has a #DarkMode ðŸ”¥ðŸ˜Ž>, <Tweet id=1492342842144006145 text=ðŸ’¯ https://t.co/vyuM3TjwgU>]\n",
      "AdrianAdewunmi\n",
      "None\n",
      "AmanKhanna\n",
      "[<Tweet id=1492570856211591176 text=Sharingâ€¦ https://t.co/ynbpBYm3yy>, <Tweet id=1490408582856200200 text=https://t.co/mLQIH73zor https://t.co/T6Q31g0l1B>, <Tweet id=1490407878397734913 text=https://t.co/KEBthBeX7p https://t.co/lKjZm0leZz>, <Tweet id=1490396298133917696 text=Artificial Intelligence for Clinical Decision Support in Critical Care\n",
      "https://t.co/xiOc60JOet>, <Tweet id=1483638975755608066 text=https://t.co/fMhBX8K8fq https://t.co/Z4fpsuJGhr>, <Tweet id=1482824017471893506 text=Cloud ML https://t.co/jkuE9x9T1x>, <Tweet id=1482516898357125121 text=https://t.co/hsYqcN69DN https://t.co/JQmezG5M9J>, <Tweet id=1482516615367376896 text=https://t.co/tT91uMyVxO https://t.co/cuTeGdMSQm>, <Tweet id=1482508323970813952 text=https://t.co/ACNEScRr1E https://t.co/TwBMzkyKJ9>, <Tweet id=1482213044801482753 text=https://t.co/lz96E8oZBp https://t.co/hbfuyN6ttG>]\n"
     ]
    }
   ],
   "source": [
    "# using Twitter API v2.0\n",
    "# https://docs.tweepy.org/en/stable/client.html?highlight=user.timeline#tweepy.Client.get_users_tweets\n",
    "\n",
    "tweet_fields = ['author_id','referenced_tweets.id','referenced_tweets.id.author_id',\n",
    "                'entities.mentions.username','attachments.poll_ids','attachments.media_keys,in_reply_to_user_id',\n",
    "                'geo.place_id']\n",
    "\n",
    "\n",
    "all_tweets = []\n",
    "for uzid, mxid, lumin in zip(userid_list, maxid_list, lumin_list):\n",
    "    print(lumin)\n",
    "    tweets = client.get_users_tweets(uzid, end_time=e_time, \n",
    "                                     since_id = mxid, \n",
    "                                     start_time = s_time, \n",
    "                                     expansions = tweet_fields,\n",
    "                                     user_auth=False)\n",
    "    print(tweets )\n",
    "    all_tweets.extend(tweets)\n",
    "        #print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45830ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Tweet id=1491681314113835009 text=Lâ€™Institut BergoniÃ©, Exolis et Synapse Medicine s'allient dans le tÃ©lÃ©suivi des patients atteints de cancer via @rteston https://t.co/nhqmTS8U3F https://t.co/bS9zFEkW0l>,\n",
       " <Tweet id=1491085678301569027 text=Nouveau DMP : le service Mon Espace SantÃ© interroge sur la sÃ©curitÃ© des donnÃ©es https://t.co/xjfRiJVJAP https://t.co/g8hJB4VoBg>,\n",
       " <Tweet id=1491083917838934025 text=Des chercheurs dÃ©veloppent un utÃ©rus artificiel gÃ©rÃ© par une IA https://t.co/U9x7aBZ8oF https://t.co/h7ABtnFnQ4>,\n",
       " <Tweet id=1490998350514200581 text=Le Pr Fabrice Denis, crÃ©ateur primÃ© de https://t.co/vRLLiar7OW : Â«Â nous ne sommes quâ€™aux balbutiements de la e-santÃ©Â Â» https://t.co/3nTEhZOC9v https://t.co/KtsPt8vakA>,\n",
       " <Tweet id=1490988107369492485 text=Le CNOM publie un guide de la santÃ© numÃ©rique via @rteston https://t.co/tX8UMGgxCB https://t.co/tOWp5vSbI7>,\n",
       " <Tweet id=1490988069939556355 text=Une nouvelle appli, truffÃ©e dâ€™IA qui sÃ©lectionne les publications mÃ©dicales qui vous concernent ! Du 100% pur jus de science gratuit ! via @Francois_BARRAU https://t.co/jpdR0DiWZo https://t.co/kJ45ROK8GS>,\n",
       " <Tweet id=1490972177637781506 text=Comment la France rattrape son retard dans le numÃ©rique en santÃ© https://t.co/ka03Z9AtWQ https://t.co/eiqkPqPIJY>,\n",
       " <Tweet id=1490744122050809866 text=Coalition Next lance un nouvel appel Ã  projets https://t.co/BJ2OzLm073 https://t.co/5QJuiByqY3>,\n",
       " <Tweet id=1490723297545314311 text=[TRIBUNE] Intelligence artificielle et e-santÃ© : vers une innovation thÃ©rapeutique socialement responsable https://t.co/VhF6PPrPHA https://t.co/d9l08yxFq6>,\n",
       " <Tweet id=1490721528832409601 text=Avec le rachat de 8fit, Withings veut se dÃ©velopper dans les services autour de la santÃ© https://t.co/aDQy1iG7UH https://t.co/L3hqN81vcY>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beba6a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'user'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/3553477964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0musers_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/3553477964.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0musers_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'user'"
     ]
    }
   ],
   "source": [
    "all_tweets[0:3]\n",
    "#users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in all_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e368b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets2 = []\n",
    "for uzid, mxid in zip(userid_list, maxid_list):\n",
    "    try:\n",
    "        tweets = get_tweets_from_user(uzid)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    all_tweets2.extend(tweets)\n",
    "        #print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbff3bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/1383017410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtemp_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_lumin_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_retweeted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweet_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_result_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/677957371.py\u001b[0m in \u001b[0;36mprocess_lumin_tweet\u001b[0;34m(status, is_retweeted)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(status)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtweet_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extended_tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'â€™'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mis_extended\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "temp_list=[]\n",
    "for tweet in all_tweets:\n",
    "    temp_list.append(process_lumin_tweet(tweet,is_retweeted=False))\n",
    "df = pd.DataFrame(temp_list, columns=[col_names])\n",
    "tweet_result_df = pd.concat([tweet_result_df, df])\n",
    "print(\"N of tweets downloaded\", len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd390836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tweets_from_user(twitter_user_name, page_limit=16, count_tweet=200):\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        - twitter_user_name: the twitter username of a user (company, etc.)\n",
    "        - page_limit: the total number of pages (max=16)\n",
    "        - count_tweet: maximum number to be retrieved from a page\n",
    "        \n",
    "    @return\n",
    "        - all the tweets from the user twitter_user_name\n",
    "    \"\"\"\n",
    "    \n",
    "    for page in Cursor(api.user_timeline, \n",
    "                        screen_name=twitter_user_name, \n",
    "                        count=count_tweet).pages(page_limit):\n",
    "        for tweet in page:\n",
    "            parsed_tweet = {}\n",
    "            parsed_tweet['date'] = tweet.created_at\n",
    "            parsed_tweet['author'] = tweet.user.name\n",
    "            parsed_tweet['twitter_name'] = tweet.user.screen_name\n",
    "            parsed_tweet['text'] = tweet.text\n",
    "            parsed_tweet['number_of_likes'] = tweet.favorite_count\n",
    "            parsed_tweet['number_of_retweets'] = tweet.retweet_count\n",
    "\n",
    "            all_tweets.append(parsed_tweet)\n",
    "\n",
    "    # Create dataframe \n",
    "    df = pd.DataFrame(all_tweets)\n",
    "\n",
    "    # Revome duplicates if there are any\n",
    "    df = df.drop_duplicates( \"text\" , keep='first')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f3b3a37",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3573914286.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/3573914286.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test = curl \"https://api.twitter.com/2/users/2474021983/tweets?start_time=2022-01-01T00:00:00.000Z&end_time=2022-02-15T00:00:00.000Z&tweet.fields=id,created_at,text,author_id,attachments,geo,lang&user.fields=id,name,username,location&media.fields=url&place.fields=country_code\" -H \"Authorization: Bearer $AAAAAAAAAAAAAAAAAAAAANmKVgEAAAAAJdfpUcZi7yJvFogOs921hxiwf20%3DhEzpHFtEBzwTj1rOJXbr2H8R2VAUJlr5HEhdcDkVvS95JXiiIO\"\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test = curl \"https://api.twitter.com/2/users/2474021983/tweets?start_time=2022-01-01T00:00:00.000Z&end_time=2022-02-15T00:00:00.000Z&tweet.fields=id,created_at,text,author_id,attachments,geo,lang&user.fields=id,name,username,location&media.fields=url&place.fields=country_code\" -H \"Authorization: Bearer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86e457b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (835869278.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/835869278.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    curl \"https://api.twitter.com/2/users/2474021983/tweets\" \\\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "curl \"https://api.twitter.com/2/users/2474021983/tweets\" -H \"Authorization: Bearer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ed6f9ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2288477334.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/xn/xzfpr8ld7clf8n67f5lmwq9w0000gp/T/ipykernel_51255/2288477334.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    r = requests.get(\"https://api.twitter.com/2/users/2474021983/tweets\" -H \"Authorization: Bearer AAAAAAAAAAAAAAAAAAAAANmKVgEAAAAAJdfpUcZi7yJvFogOs921hxiwf20%3DhEzpHFtEBzwTj1rOJXbr2H8R2VAUJlr5HEhdcDkVvS95JXiiIO\")\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://api.twitter.com/2/users/2474021983/tweets\" -H \"Authorization: Bearer \n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae05a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"https://api.twitter.com/2/tweets?ids=1261326399320715264,1278347468690915330\" \\\n",
    "  -H \"Authorization: Bearer \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
